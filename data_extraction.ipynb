{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Camino de Santiago - Data Collector**\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Welcome to the \"Camino de Santiago Data Collector\" Notebook. This interactive tool is designed to collect statistical data on pilgrims traveling the Camino de Santiago. By leveraging an API provided by the Cathedral of Santiago, this notebook streamlines the process of data collection, processing, and transformation to gain insights into the pilgrimages.\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "The primary goal of this notebook is to provide a structured and automated method for data collection, enabling analysts and enthusiasts to discover trends and patterns in pilgrim activities. The data gathered can be utilized for reporting, academic research, or to create dashboards for visual representations.\n",
    "\n",
    "### **Structure of the Notebook**\n",
    "\n",
    "The notebook is organized into several sections, each dedicated to a specific task within the data processing workflow:\n",
    "\n",
    "- **Load Libraries:** Import all necessary libraries for data handling and define parameters.\n",
    "- **Create Dataframes:** Build a data structure to store the retrieved information.\n",
    "- **Define Functions:** Develop functions for data retrieval and preprocessing.\n",
    "- **Data Transformation:** Transform and clean the data for analysis.\n",
    "- **Save the Data:** Store the collected data in an Excel file and multiple CSV files.\n",
    "\n",
    "### **How to Use**\n",
    "\n",
    "After defining the parameters, the notebook should run from top to bottom without any further interaction.\n",
    "\n",
    "### **API End of Service**\n",
    "\n",
    "Unfortunately, the API ceased functioning in May 2023. Therefore, the current data cannot be fetched by this notebook.\n",
    "\n",
    "We extend our gratitude to the [Office of the Pilgrim in Santiago](https://www.notion.so/Hubvisory-da7f22856fb9482d883af0a55d3c2cd5?pvs=21) for providing the data and to Kaggle user [Guillermo Ibarra](https://www.kaggle.com/code/guillermoibarra/camino-de-santiago-async-restful-extract)  for the foundational work that inspired this notebook.\n",
    "\n",
    "Best of luck with your analysis of the Camino de Santiago pilgrim data, and a heartfelt \"Buen Camino\" to all the pilgrims on their journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 1:__ Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                       # To work with time objects\n",
    "import json                       # To process returned JSON data\n",
    "import pandas as pd               # To work with dataframes\n",
    "import asyncio                    # To make async requests\n",
    "import httpx                      # To make requests to Cathedral URL (alternative to requests with async support)\n",
    "import datetime                   # To work with datetime objects\n",
    "import openpyxl                   # To save to Excel files\n",
    "import os                         # To work with files and directories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Some Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Cathedral API in Santiago de Compostela\n",
    "base_url = 'https://catedral.df-server.info/ws/wsCatedral.asmx'\n",
    "\n",
    "# Define the start and end dates for the data query\n",
    "data_start_date = datetime.date(2004, 1, 1)  # Start date is January 2004\n",
    "data_end_date = datetime.date.today()  # Use today's date as the end date\n",
    "\n",
    "# Output path for csv files\n",
    "save_path_csv = f\"/home/david/code/projects/CaminoStats/data/csv_files/Caminostats_{data_start_date}_{data_end_date}/\"\n",
    "\n",
    "# Output path and name for Excel file\n",
    "save_path_xl = \"/home/david/code/projects/CaminoStats/data/exel_files/\"\n",
    "filename_xlsx = f\"Caminostats_{data_start_date}_{data_end_date}.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 2:__ Creating a dict of dataframes to hold the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes to fill\n",
    "\n",
    "tablelist = [\n",
    "    'Autonomias',\n",
    "    'Caminos',\n",
    "    'Continentes',\n",
    "    'Edades',\n",
    "    'Grupos',\n",
    "    'Medios',\n",
    "    'Motivos',\n",
    "    'Paises',\n",
    "    'Procedencias',\n",
    "    'Sexos'\n",
    "]\n",
    "\n",
    "# Define the common columns for the dataframes\n",
    "common_columns = ['id', 'Anho', 'Mes', 'Nombre', 'Total', 'Porcentaje']\n",
    "\n",
    "# Define a dictionary to hold all the DataFrames\n",
    "dataframes = {\n",
    "    'Totals': pd.DataFrame(columns=['Anho', 'Mes', 'Identificador', 'TotalRegistros']),\n",
    "    # Other DataFrame names can follow the same naming convention as 'tablelist'\n",
    "}\n",
    "\n",
    "# Create a DataFrame for each item in tablelist and add it to the dictionary\n",
    "for table_name in tablelist:  # Skipping the first three items as they are already accounted for\n",
    "    dataframes[table_name] = pd.DataFrame(columns=common_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 3:__ Define functions that calculate the valid range of dates that may be retrieved from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the range of valid months between two dates\n",
    "def range_of_months(start_date, end_date):\n",
    "    months = []\n",
    "    # Loop from start to end month, converting the month number back to year and month\n",
    "    for month_num in range(start_date.year * 12 + start_date.month - 1, end_date.year * 12 + end_date.month):\n",
    "        year, month = divmod(month_num, 12)\n",
    "        months.append([year, month + 1])  # Add 1 because months are 1-indexed\n",
    "    return months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of year and month pairs between the start and end dates\n",
    "year_months = range_of_months(data_start_date, data_end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 4:__ Define functions that concatenate newly retrieved data to previously retrieved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add prefixed columns for ID, year, and month to a DataFrame\n",
    "def add_prefixed_columns(idx, yr, mnth, df):\n",
    "    df['id'] = idx\n",
    "    df['Anho'] = yr\n",
    "    df['Mes'] = mnth\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add new data to a running totals DataFrame\n",
    "def add_to_dataframe(df_running_totals, yr, mnth, df_to_add):\n",
    "    idx = f\"{yr}{str(mnth).zfill(2)}\"\n",
    "    add_prefixed_columns(idx, yr, mnth, df_to_add)\n",
    "    return pd.concat([df_running_totals, df_to_add], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 5:__ Defines function that retrieves, splits and converts json data to the various dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async function that requests data from the Cathedral's server\n",
    "# waits for response from server before it continues with requests to avoid empty responses (a \"denial of service\" defense mechanism? )\n",
    "\n",
    "async def get_data(month, year, dataframes):\n",
    "    url = f\"{base_url}/ObtenerEstadisticasMes?eAnho={year}&eMes={month}\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url)\n",
    "        if response.status_code == 200:\n",
    "            json_data_chunk = response.json()\n",
    "            if json_data_chunk['Caminos'] == []:\n",
    "                print(f\"No data for month: {month}, year: {year}\")\n",
    "            else:\n",
    "                dataframes['Totals'] = add_to_dataframe(dataframes['Totals'], year, month, pd.DataFrame({'TotalRegistros': [json_data_chunk['TotalRegistros']],'Identificador': [json_data_chunk['Identificador']]}))\n",
    "                keylist = ['TotalRegistros','Identificador','Anho','Mes']\n",
    "                for key in json_data_chunk.keys():\n",
    "                    #print(key)\n",
    "                    if key in tablelist:\n",
    "                        #print(f\"Adding data for {key}\")\n",
    "                        dataframes[key] = add_to_dataframe(dataframes[key], year, month, pd.DataFrame(json_data_chunk[key]))\n",
    "                        #print(dataframes[key].tail())\n",
    "                print(f\"Got data for month: {month}, year: {year}\")\n",
    "        else:\n",
    "            print(f\"Failed to get data for month: {month}, year: {year}, Status Code: {response.status_code}\")\n",
    "    return dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got data for month: 1, year: 2004\n",
      "Got data for month: 2, year: 2004\n",
      "Got data for month: 3, year: 2004\n",
      "Got data for month: 4, year: 2004\n",
      "Got data for month: 5, year: 2004\n",
      "Got data for month: 6, year: 2004\n",
      "Got data for month: 7, year: 2004\n",
      "Got data for month: 8, year: 2004\n",
      "Got data for month: 9, year: 2004\n",
      "Got data for month: 10, year: 2004\n",
      "Got data for month: 11, year: 2004\n",
      "Got data for month: 12, year: 2004\n",
      "Got data for month: 1, year: 2005\n",
      "Got data for month: 2, year: 2005\n",
      "Got data for month: 3, year: 2005\n",
      "Got data for month: 4, year: 2005\n",
      "Got data for month: 5, year: 2005\n",
      "Got data for month: 6, year: 2005\n",
      "Got data for month: 7, year: 2005\n",
      "Got data for month: 8, year: 2005\n",
      "Got data for month: 9, year: 2005\n",
      "Got data for month: 10, year: 2005\n",
      "Got data for month: 11, year: 2005\n",
      "Got data for month: 12, year: 2005\n",
      "Got data for month: 1, year: 2006\n",
      "Got data for month: 2, year: 2006\n",
      "Got data for month: 3, year: 2006\n",
      "Got data for month: 4, year: 2006\n",
      "Got data for month: 5, year: 2006\n",
      "Got data for month: 6, year: 2006\n",
      "Got data for month: 7, year: 2006\n",
      "Got data for month: 8, year: 2006\n",
      "Got data for month: 9, year: 2006\n",
      "Got data for month: 10, year: 2006\n",
      "Got data for month: 11, year: 2006\n",
      "Got data for month: 12, year: 2006\n",
      "Got data for month: 1, year: 2007\n",
      "Got data for month: 2, year: 2007\n",
      "Got data for month: 3, year: 2007\n",
      "Got data for month: 4, year: 2007\n",
      "Got data for month: 5, year: 2007\n",
      "Got data for month: 6, year: 2007\n",
      "Got data for month: 7, year: 2007\n",
      "Got data for month: 8, year: 2007\n",
      "Got data for month: 9, year: 2007\n",
      "Got data for month: 10, year: 2007\n",
      "Got data for month: 11, year: 2007\n",
      "Got data for month: 12, year: 2007\n",
      "Got data for month: 1, year: 2008\n",
      "Got data for month: 2, year: 2008\n",
      "Got data for month: 3, year: 2008\n",
      "Got data for month: 4, year: 2008\n",
      "Got data for month: 5, year: 2008\n",
      "Got data for month: 6, year: 2008\n",
      "Got data for month: 7, year: 2008\n",
      "Got data for month: 8, year: 2008\n",
      "Got data for month: 9, year: 2008\n",
      "Got data for month: 10, year: 2008\n",
      "Got data for month: 11, year: 2008\n",
      "Got data for month: 12, year: 2008\n",
      "Got data for month: 1, year: 2009\n",
      "Got data for month: 2, year: 2009\n",
      "Got data for month: 3, year: 2009\n",
      "Got data for month: 4, year: 2009\n",
      "Got data for month: 5, year: 2009\n",
      "Got data for month: 6, year: 2009\n",
      "Got data for month: 7, year: 2009\n",
      "Got data for month: 8, year: 2009\n",
      "Got data for month: 9, year: 2009\n",
      "Got data for month: 10, year: 2009\n",
      "Got data for month: 11, year: 2009\n",
      "Got data for month: 12, year: 2009\n",
      "Got data for month: 1, year: 2010\n",
      "Got data for month: 2, year: 2010\n",
      "Got data for month: 3, year: 2010\n",
      "Got data for month: 4, year: 2010\n",
      "Got data for month: 5, year: 2010\n",
      "Got data for month: 6, year: 2010\n",
      "Got data for month: 7, year: 2010\n",
      "Got data for month: 8, year: 2010\n",
      "Got data for month: 9, year: 2010\n",
      "Got data for month: 10, year: 2010\n",
      "Got data for month: 11, year: 2010\n",
      "Got data for month: 12, year: 2010\n",
      "Got data for month: 1, year: 2011\n",
      "Got data for month: 2, year: 2011\n",
      "Got data for month: 3, year: 2011\n",
      "Got data for month: 4, year: 2011\n",
      "Got data for month: 5, year: 2011\n",
      "Got data for month: 6, year: 2011\n",
      "Got data for month: 7, year: 2011\n",
      "Got data for month: 8, year: 2011\n",
      "Got data for month: 9, year: 2011\n",
      "Got data for month: 10, year: 2011\n",
      "Got data for month: 11, year: 2011\n",
      "Got data for month: 12, year: 2011\n",
      "Got data for month: 1, year: 2012\n",
      "Got data for month: 2, year: 2012\n",
      "Got data for month: 3, year: 2012\n",
      "Got data for month: 4, year: 2012\n",
      "Got data for month: 5, year: 2012\n",
      "Got data for month: 6, year: 2012\n",
      "Got data for month: 7, year: 2012\n",
      "Got data for month: 8, year: 2012\n",
      "Got data for month: 9, year: 2012\n",
      "Got data for month: 10, year: 2012\n",
      "Got data for month: 11, year: 2012\n",
      "Got data for month: 12, year: 2012\n",
      "Got data for month: 1, year: 2013\n",
      "Got data for month: 2, year: 2013\n",
      "Got data for month: 3, year: 2013\n",
      "Got data for month: 4, year: 2013\n",
      "Got data for month: 5, year: 2013\n",
      "Got data for month: 6, year: 2013\n",
      "Got data for month: 7, year: 2013\n",
      "Got data for month: 8, year: 2013\n",
      "Got data for month: 9, year: 2013\n",
      "Got data for month: 10, year: 2013\n",
      "Got data for month: 11, year: 2013\n",
      "Got data for month: 12, year: 2013\n",
      "Got data for month: 1, year: 2014\n",
      "Got data for month: 2, year: 2014\n",
      "Got data for month: 3, year: 2014\n",
      "Got data for month: 4, year: 2014\n",
      "Got data for month: 5, year: 2014\n",
      "Got data for month: 6, year: 2014\n",
      "Got data for month: 7, year: 2014\n",
      "Got data for month: 8, year: 2014\n",
      "Got data for month: 9, year: 2014\n",
      "Got data for month: 10, year: 2014\n",
      "Got data for month: 11, year: 2014\n",
      "Got data for month: 12, year: 2014\n",
      "Got data for month: 1, year: 2015\n",
      "Got data for month: 2, year: 2015\n",
      "Got data for month: 3, year: 2015\n",
      "Got data for month: 4, year: 2015\n",
      "Got data for month: 5, year: 2015\n",
      "Got data for month: 6, year: 2015\n",
      "Got data for month: 7, year: 2015\n",
      "Got data for month: 8, year: 2015\n",
      "Got data for month: 9, year: 2015\n",
      "Got data for month: 10, year: 2015\n",
      "Got data for month: 11, year: 2015\n",
      "Got data for month: 12, year: 2015\n",
      "Got data for month: 1, year: 2016\n",
      "Got data for month: 2, year: 2016\n",
      "Got data for month: 3, year: 2016\n",
      "Got data for month: 4, year: 2016\n",
      "Got data for month: 5, year: 2016\n",
      "Got data for month: 6, year: 2016\n",
      "Got data for month: 7, year: 2016\n",
      "Got data for month: 8, year: 2016\n",
      "Got data for month: 9, year: 2016\n",
      "Got data for month: 10, year: 2016\n",
      "Got data for month: 11, year: 2016\n",
      "Got data for month: 12, year: 2016\n",
      "Got data for month: 1, year: 2017\n",
      "Got data for month: 2, year: 2017\n",
      "Got data for month: 3, year: 2017\n",
      "Got data for month: 4, year: 2017\n",
      "Got data for month: 5, year: 2017\n",
      "Got data for month: 6, year: 2017\n",
      "Got data for month: 7, year: 2017\n",
      "Got data for month: 8, year: 2017\n",
      "Got data for month: 9, year: 2017\n",
      "Got data for month: 10, year: 2017\n",
      "Got data for month: 11, year: 2017\n",
      "Got data for month: 12, year: 2017\n",
      "Got data for month: 1, year: 2018\n",
      "Got data for month: 2, year: 2018\n",
      "Got data for month: 3, year: 2018\n",
      "Got data for month: 4, year: 2018\n",
      "Got data for month: 5, year: 2018\n",
      "Got data for month: 6, year: 2018\n",
      "Got data for month: 7, year: 2018\n",
      "Got data for month: 8, year: 2018\n",
      "Got data for month: 9, year: 2018\n",
      "Got data for month: 10, year: 2018\n",
      "Got data for month: 11, year: 2018\n",
      "Got data for month: 12, year: 2018\n",
      "Got data for month: 1, year: 2019\n",
      "Got data for month: 2, year: 2019\n",
      "Got data for month: 3, year: 2019\n",
      "Got data for month: 4, year: 2019\n",
      "Got data for month: 5, year: 2019\n",
      "Got data for month: 6, year: 2019\n",
      "Got data for month: 7, year: 2019\n",
      "Got data for month: 8, year: 2019\n",
      "Got data for month: 9, year: 2019\n",
      "Got data for month: 10, year: 2019\n",
      "Got data for month: 11, year: 2019\n",
      "Got data for month: 12, year: 2019\n",
      "Got data for month: 1, year: 2020\n",
      "Got data for month: 2, year: 2020\n",
      "Got data for month: 3, year: 2020\n",
      "No data for month: 4, year: 2020\n",
      "No data for month: 5, year: 2020\n",
      "Got data for month: 6, year: 2020\n",
      "Got data for month: 7, year: 2020\n",
      "Got data for month: 8, year: 2020\n",
      "Got data for month: 9, year: 2020\n",
      "Got data for month: 10, year: 2020\n",
      "Got data for month: 11, year: 2020\n",
      "Got data for month: 12, year: 2020\n",
      "Got data for month: 1, year: 2021\n",
      "Got data for month: 2, year: 2021\n",
      "Got data for month: 3, year: 2021\n",
      "Got data for month: 4, year: 2021\n",
      "Got data for month: 5, year: 2021\n",
      "Got data for month: 6, year: 2021\n",
      "Got data for month: 7, year: 2021\n",
      "Got data for month: 8, year: 2021\n",
      "Got data for month: 9, year: 2021\n",
      "Got data for month: 10, year: 2021\n",
      "Got data for month: 11, year: 2021\n",
      "Got data for month: 12, year: 2021\n",
      "Got data for month: 1, year: 2022\n",
      "Got data for month: 2, year: 2022\n",
      "Got data for month: 3, year: 2022\n",
      "Got data for month: 4, year: 2022\n",
      "Got data for month: 5, year: 2022\n",
      "Got data for month: 6, year: 2022\n",
      "Got data for month: 7, year: 2022\n",
      "Got data for month: 8, year: 2022\n",
      "Got data for month: 9, year: 2022\n",
      "Got data for month: 10, year: 2022\n",
      "Got data for month: 11, year: 2022\n",
      "Got data for month: 12, year: 2022\n",
      "Got data for month: 1, year: 2023\n",
      "Got data for month: 2, year: 2023\n",
      "No data for month: 3, year: 2023\n",
      "Got data for month: 4, year: 2023\n",
      "No data for month: 5, year: 2023\n",
      "No data for month: 6, year: 2023\n",
      "No data for month: 7, year: 2023\n",
      "No data for month: 8, year: 2023\n",
      "No data for month: 9, year: 2023\n",
      "No data for month: 10, year: 2023\n",
      "No data for month: 11, year: 2023\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of year and month pairs between the start and end dates\n",
    "# If already data exists, start from the last month in the data\n",
    "if len(dataframes['Totals'])>0:\n",
    "    data_start_date = datetime.date(int(dataframes['Totals'].tail(1)['id'].values[0][:4]), int(dataframes['Totals'].tail(1)['id'].values[0][4:])+1, 1)\n",
    "\n",
    "year_months = range_of_months(data_start_date, data_end_date)\n",
    "\n",
    "# Loop through each year and month pair to get data\n",
    "for year, month in year_months:\n",
    "    result = await get_data(month, year, dataframes)\n",
    "    if not result:\n",
    "        print('Breaking loop due to an error')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_backup = dataframes.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes = dataframe_backup.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid extension for engine 'openpyxl': 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/david/code/projects/CaminoStats/data_extraction.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/code/projects/CaminoStats/data_extraction.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m pd\u001b[39m.\u001b[39;49mExcelWriter(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00msave_path_xl\u001b[39m}\u001b[39;49;00m\u001b[39mbackup_\u001b[39;49m\u001b[39m{\u001b[39;49;00mfilename\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m writer:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/code/projects/CaminoStats/data_extraction.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m dataframe_backup\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/david/code/projects/CaminoStats/data_extraction.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m         dataframe_backup[key]\u001b[39m.\u001b[39mto_excel(writer, sheet_name\u001b[39m=\u001b[39mkey)\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:53\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworkbook\u001b[39;00m \u001b[39mimport\u001b[39;00m Workbook\n\u001b[1;32m     51\u001b[0m engine_kwargs \u001b[39m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[0;32m---> 53\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     54\u001b[0m     path,\n\u001b[1;32m     55\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m     56\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m     57\u001b[0m     if_sheet_exists\u001b[39m=\u001b[39;49mif_sheet_exists,\n\u001b[1;32m     58\u001b[0m     engine_kwargs\u001b[39m=\u001b[39;49mengine_kwargs,\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[39m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m# the file and later write to it\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:  \u001b[39m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/excel/_base.py:1092\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1091\u001b[0m     ext \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(path)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1092\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_extension(ext)\n\u001b[1;32m   1094\u001b[0m \u001b[39m# use mode to open the file\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.pyenv/versions/sandbox/lib/python3.10/site-packages/pandas/io/excel/_base.py:1192\u001b[0m, in \u001b[0;36mExcelWriter.check_extension\u001b[0;34m(cls, ext)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# error: \"Callable[[ExcelWriter], Any]\" has no attribute \"__iter__\" (not\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m#  iterable)\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1189\u001b[0m     ext \u001b[39min\u001b[39;00m extension\n\u001b[1;32m   1190\u001b[0m     \u001b[39mfor\u001b[39;00m extension \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msupported_extensions  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m ):\n\u001b[0;32m-> 1192\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid extension for engine \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mext\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid extension for engine 'openpyxl': 'csv'"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(f\"{save_path_xl}backup_{filename}\", engine=\"openpyxl\") as writer:\n",
    "    for key in dataframe_backup.keys():\n",
    "        dataframe_backup[key].to_excel(writer, sheet_name=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 6:__ Rename and reorganize the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping current column names to the new names in proper case\n",
    "column_names = {\n",
    "    \"id\": \"ID\",\n",
    "    \"Anho\": \"Year\",\n",
    "    \"Mes\": \"Month\",\n",
    "    \"Nombre\": \"Description\",\n",
    "    \"Total\": \"Total\",\n",
    "    \"Porcentaje\": \"Percentage\",\n",
    "    \"TotalRegistros\": \"TotalRecords\",\n",
    "    \"Identificador\": \"Identifier\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename dataframe columns according to a given mapping\n",
    "def rename_columns(df, new_column_names):\n",
    "    return df.rename(columns=new_column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in all dataframes\n",
    "for key in dataframes.keys():\n",
    "    dataframes[key] = rename_columns(dataframes[key], column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__edit Totals Table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['Totals'] = dataframes['Totals'].set_index(['ID', 'Year', 'Month']).rename(columns={'TotalRecords': 'Total'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200401</th>\n",
       "      <th>2004</th>\n",
       "      <th>1</th>\n",
       "      <td>200401</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200402</th>\n",
       "      <th>2004</th>\n",
       "      <th>2</th>\n",
       "      <td>200402</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200403</th>\n",
       "      <th>2004</th>\n",
       "      <th>3</th>\n",
       "      <td>200403</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200404</th>\n",
       "      <th>2004</th>\n",
       "      <th>4</th>\n",
       "      <td>200404</td>\n",
       "      <td>15554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200405</th>\n",
       "      <th>2004</th>\n",
       "      <th>5</th>\n",
       "      <td>200405</td>\n",
       "      <td>16860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202211</th>\n",
       "      <th>2022</th>\n",
       "      <th>11</th>\n",
       "      <td>202211</td>\n",
       "      <td>11283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202212</th>\n",
       "      <th>2022</th>\n",
       "      <th>12</th>\n",
       "      <td>202212</td>\n",
       "      <td>4683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202301</th>\n",
       "      <th>2023</th>\n",
       "      <th>1</th>\n",
       "      <td>202301</td>\n",
       "      <td>2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202302</th>\n",
       "      <th>2023</th>\n",
       "      <th>2</th>\n",
       "      <td>202302</td>\n",
       "      <td>2856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202304</th>\n",
       "      <th>2023</th>\n",
       "      <th>4</th>\n",
       "      <td>202304</td>\n",
       "      <td>24176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Identifier  Total\n",
       "ID     Year Month                  \n",
       "200401 2004 1         200401    643\n",
       "200402 2004 2         200402   1401\n",
       "200403 2004 3         200403   3105\n",
       "200404 2004 4         200404  15554\n",
       "200405 2004 5         200405  16860\n",
       "...                      ...    ...\n",
       "202211 2022 11        202211  11283\n",
       "202212 2022 12        202212   4683\n",
       "202301 2023 1         202301   2028\n",
       "202302 2023 2         202302   2856\n",
       "202304 2023 4         202304  24176\n",
       "\n",
       "[229 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['Totals']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 8:__ Converts tables format from __\"long\"__ to __\"wide\"__, in this step all nulls are converted to zero because these are numeric counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__For df Autonomias__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pivot table directly with summation\n",
    "autonomous_coms_wide_df = pd.pivot_table(           # Create a pivot table\n",
    "                dataframes['Autonomias'],           # Use the 'Autonomias' dataframe\n",
    "                values='Total',                     # Use the 'Total' column for the values\n",
    "                index=['ID', 'Year', 'Month'],      # Use the 'ID', 'Year', and 'Month' columns for the index\n",
    "                columns='Description',              # Use the 'Description' column for the columns\n",
    "                aggfunc='sum',                      # Aggregation function is required but will not change the output if no duplicates\n",
    "                fill_value=0                        # Replace NaN values with 0 directly\n",
    "                )\n",
    "\n",
    "# pop df Autonomias\n",
    "dataframes.pop('Autonomias', None)\n",
    "\n",
    "# Reorder columns if necessary and add the 'Total' column\n",
    "cols = autonomous_coms_wide_df.columns.tolist()\n",
    "\n",
    "# This line might be redundant if the column order is already correct.\n",
    "autonomous_coms_wide_df = autonomous_coms_wide_df[cols]\n",
    "autonomous_coms_wide_df['Total'] = autonomous_coms_wide_df.sum(axis=1)\n",
    "\n",
    "# Update the `dataframes` dictionary\n",
    "dataframes['Autonomous Communities'] = autonomous_coms_wide_df\n",
    "del autonomous_coms_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Caminos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "routes_wide_df = pd.pivot_table(\n",
    "    dataframes['Caminos'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# pop df Caminos\n",
    "dataframes.pop('Caminos', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "routes_wide_df['Total'] = routes_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "routes_translation = {\n",
    "    'Frances-Camino de': 'Camino Francés',\n",
    "    'Via de la Plata': 'Vía de la Plata',\n",
    "    'Primitivo-Camino': 'Camino Primitivo',\n",
    "    'Portugues-Camino': 'Camino Portugués',\n",
    "    'Norte-Camino de': 'Camino del Norte',\n",
    "    'Ingles-Camino': 'Camino Inglés',\n",
    "    'Costa Camino Portugues': 'Camino Portugués de la Costa',\n",
    "    'Otros caminos': 'Other Ways',\n",
    "    'Muxia-Finisterre': 'Camino de Finisterre y Muxía',\n",
    "    'Invierno de Camino': 'Winter Way (Camino de Invierno)',\n",
    "    'Resto': 'Others',\n",
    "    'Geira e Arrieiros': 'Geira and Arrieiros Way (Camino de Geira e Arrieiros)',\n",
    "    'Muros - Noia Camino': 'Muros-Noia Way (Camino de Muros - Noia)',\n",
    "    'Miñoto Ribeiro': 'Miñoto Ribeiro Way (Camino de Miñoto Ribeiro)',\n",
    "    'Camino del Barbanza': 'Barbanza Way (Camino del Barbanza)',\n",
    "    'Camino del Mar': 'Way of the Sea (Camino del Mar)',\n",
    "    'Camino olvidado': 'Forgotten Way (Camino Olvidado)',\n",
    "    'San Salvador': 'San Salvador Way (Camino de San Salvador)',\n",
    "    'Vía Céltica': 'Celtic Way (Vía Céltica)',\n",
    "    'San Rosendo': 'San Rosendo Way (Camino de San Rosendo)',\n",
    "    'Sin establecer': 'Not Established'\n",
    "}\n",
    "routes_wide_df.rename(columns=routes_translation, inplace=True)\n",
    "\n",
    "# Update the `dataframes` dictionary and delete the temporary dataframe\n",
    "dataframes['Routes'] = routes_wide_df\n",
    "del routes_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Continents__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pivot table directly with summation\n",
    "continents_wide_df = pd.pivot_table(\n",
    "    dataframes['Continentes'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "continents_wide_df['Total'] = continents_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "column_mapping = {\n",
    "    'Europa': 'Europe',\n",
    "    'América del Norte': 'North America',\n",
    "    'Oceanía': 'Oceania',\n",
    "    'América del Sur': 'South America',\n",
    "    'Asia': 'Asia',\n",
    "    'África': 'Africa',\n",
    "    'Resto': 'Other',\n",
    "    'Sin establecer': 'Not specified'\n",
    "}\n",
    "\n",
    "\n",
    "continents_wide_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "\n",
    "# Update the `dataframes` dictionary and delete the temporary dataframe\n",
    "dataframes['Continentes'] = continents_wide_df\n",
    "\n",
    "\n",
    "# It seems that there is 2 Africas, so we need to sum them\n",
    "# Calculate the sum for Africa and add it as a new column\n",
    "africa = dataframes['Continentes']['Africa'].sum(axis=1)\n",
    "dataframes['Continentes'].drop('Africa', axis=1, inplace=True)\n",
    "\n",
    "dataframes['Continentes']['Africa'] = africa\n",
    "\n",
    "# Reorder and select only the required columns\n",
    "columns_order = ['Europe', 'North America', 'South America', 'Asia', 'Africa', 'Oceania', 'Other', 'Not specified', 'Total']\n",
    "dataframes['Continentes'] = dataframes['Continentes'][columns_order]\n",
    "\n",
    "\n",
    "del continents_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Edades__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot without groupby if there are no duplicate combinations\n",
    "ages_wide_df = pd.pivot_table(\n",
    "    dataframes['Edades'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# pop df Edades\n",
    "dataframes.pop('Edades', None)\n",
    "\n",
    "# Add the 'Total' column as the sum of the rows\n",
    "ages_wide_df['Total'] = ages_wide_df.sum(axis=1)\n",
    "\n",
    "# Combine 'Sin establecer' and 'Resto' columns into 'Not defined'\n",
    "columns_to_combine = ['Sin establecer', 'Resto']\n",
    "ages_wide_df['Not defined'] = 0\n",
    "\n",
    "for column in columns_to_combine:\n",
    "    if column in ages_wide_df.columns:\n",
    "        ages_wide_df['Not defined'] += ages_wide_df.pop(column)  # Use pop to add and remove the column\n",
    "\n",
    "# Ensure the columns are in the desired order\n",
    "order = ['30-60', '<30', '>60', 'Not defined', 'Total']\n",
    "\n",
    "# Reindex columns based on the 'order' list, missing columns will be filled with NaN, then replace NaN with 0\n",
    "ages_wide_df = ages_wide_df.reindex(order, axis=1, fill_value=0)\n",
    "\n",
    "# Update the `dataframes` dictionary and delete the temporary dataframe\n",
    "dataframes['Ages'] = ages_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Grupos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to wide format\n",
    "groups_wide_df = pd.pivot_table(\n",
    "    dataframes['Grupos'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',  # sum is used but has no effect if there are no duplicates\n",
    "    fill_value=0    # Replace NaN with 0\n",
    ")\n",
    "# pop df Grupos\n",
    "dataframes.pop('Grupos', None)\n",
    "\n",
    "# Add the 'Total' column as the sum of the other columns\n",
    "groups_wide_df['Total'] = groups_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "groups_column_mapping = {\n",
    "    'Estudiantes': 'Students',\n",
    "    'Obreros': 'Workers',\n",
    "    'Liberales': 'Freelancers',\n",
    "    'Empleados': 'Employees',\n",
    "    'Profesores': 'Teachers',\n",
    "    'Jubilados': 'Retirees',\n",
    "    'Tecnicos': 'Technicians',\n",
    "    'Funcionarios': 'Civil Servants',\n",
    "    'Parados': 'Unemployed',\n",
    "    'Amas de Casa': 'Housewives',\n",
    "    'Resto': 'Others',\n",
    "    'Agricultores': 'Farmers',\n",
    "    'Artistas': 'Artists',\n",
    "    'Deportistas': 'Athletes',\n",
    "    'Directivos': 'Executives',\n",
    "    'Marinos': 'Sailors',\n",
    "    'Religiosas/os': 'Religious',\n",
    "    'Sacerdotes': 'Priests',\n",
    "    'Sin establecer': 'Not specified'\n",
    "}\n",
    "groups_wide_df.rename(columns=groups_column_mapping, inplace=True)\n",
    "\n",
    "dataframes['Groups'] = groups_wide_df\n",
    "del groups_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Medios__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "transportation_wide_df = pd.pivot_table(\n",
    "    dataframes['Medios'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',  # Summing the total values\n",
    "    fill_value=0    # Replacing NaN values with 0 directly\n",
    ")\n",
    "\n",
    "# pop df Medios\n",
    "dataframes.pop('Medios', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "transportation_wide_df['Total'] = transportation_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "transportation_column_mapping = {\n",
    "    'Pie': 'On Foot',\n",
    "    'Bicicleta': 'Bicycle',\n",
    "    'Caballo': 'Horse',\n",
    "    'Silla de ruedas': 'Wheelchair',\n",
    "    'Sin establecer': 'Not specified',\n",
    "    'Vela': 'Sailboat',\n",
    "}\n",
    "transportation_wide_df.rename(columns=transportation_column_mapping, inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "dataframes['Transportation'] = transportation_wide_df\n",
    "del transportation_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Motivos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "motives_wide_df = pd.pivot_table(\n",
    "    dataframes['Motivos'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',  # Summing the total values\n",
    "    fill_value=0    # Replacing NaN values with 0 directly\n",
    ")\n",
    "\n",
    "# Remove the original DataFrame from the dictionary\n",
    "dataframes.pop('Motivos', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "motives_wide_df['Total'] = motives_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "motives_column_mapping = {\n",
    "    'Religioso': 'Religious',\n",
    "    'Religioso y otros': 'Religious and others',\n",
    "    'No religioso': 'Non-religious',\n",
    "    'Sin establecer' : 'Not specified'\n",
    "}\n",
    "motives_wide_df.rename(columns=motives_column_mapping, inplace=True)\n",
    "\n",
    "  # Use None to avoid KeyError if the key is not found\n",
    "\n",
    "# Assign the resulting DataFrame back to the dataframes dictionary\n",
    "dataframes['Motives'] = motives_wide_df\n",
    "del motives_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Paises__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "countries_wide_df = pd.pivot_table(\n",
    "    dataframes['Paises'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',  # Summing the total values\n",
    "    fill_value=0    # Replacing NaN values with 0 directly\n",
    ")\n",
    "\n",
    "# Remove the original DataFrame from the dictionary\n",
    "dataframes.pop('Paises', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "countries_wide_df['Total'] = countries_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "countries_column_mapping = {\n",
    "    'España': 'Spain',\n",
    "    'Alemania': 'Germany',\n",
    "    'Estados Unidos': 'United States',\n",
    "    'Italia': 'Italy',\n",
    "    'Australia': 'Australia',\n",
    "    'Francia': 'France',\n",
    "    'Suiza': 'Switzerland',\n",
    "    'Japón': 'Japan',\n",
    "    'Reino Unido': 'United Kingdom',\n",
    "    'Holanda': 'Netherlands',\n",
    "    'Portugal': 'Portugal',\n",
    "    'Finlandia': 'Finland',\n",
    "    'Brasil': 'Brazil',\n",
    "    'México': 'Mexico',\n",
    "    'Resto': 'Others',\n",
    "    'Argentina': 'Argentina',\n",
    "    'Austria': 'Austria',\n",
    "    'Belgica': 'Belgium',\n",
    "    'Belice': 'Belize',\n",
    "    'Bulgaria': 'Bulgaria',\n",
    "    'Bélgica': 'Belgium',\n",
    "    'Canada': 'Canada',\n",
    "    'Chile': 'Chile',\n",
    "    'China': 'China',\n",
    "    'Colombia': 'Colombia',\n",
    "    'Korea': 'Korea',\n",
    "    'Denmark': 'Denmark',\n",
    "    'Eslovaquia': 'Slovakia',\n",
    "    'Estonia': 'Estonia',\n",
    "    'Hungría': 'Hungary',\n",
    "    'Indonesia': 'Indonesia',\n",
    "    'Ireland': 'Ireland',\n",
    "    'Irán': 'Iran',\n",
    "    'Islandia': 'Iceland',\n",
    "    'Israel': 'Israel',\n",
    "    'Lituania': 'Lithuania',\n",
    "    'Perú': 'Peru',\n",
    "    'Poland': 'Poland',\n",
    "    'Puerto Rico': 'Puerto Rico',\n",
    "    'Czech Republic': 'Czech Republic',\n",
    "    'Rumania': 'Romania',\n",
    "    'Russia': 'Russia',\n",
    "    'Singapur': 'Singapore',\n",
    "    'Sudáfrica': 'South Africa',\n",
    "    'Suecia': 'Sweden',\n",
    "    'Taiwan': 'Taiwan',\n",
    "    'Ucrania': 'Ukraine',\n",
    "    'Uruguay': 'Uruguay',\n",
    "    'Venezuela': 'Venezuela'\n",
    "}\n",
    "\n",
    "countries_wide_df.rename(columns=countries_column_mapping, inplace=True)\n",
    "\n",
    "# Assign the resulting DataFrame back to the dataframes dictionary\n",
    "dataframes['Countries'] = countries_wide_df\n",
    "del countries_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Procedencias__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "origin_wide_df = pd.pivot_table(\n",
    "    dataframes['Procedencias'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Remove the original DataFrame from the dictionary\n",
    "dataframes.pop('Procedencias', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "origin_wide_df['Total'] = origin_wide_df.sum(axis=1)\n",
    "\n",
    "# Assign the resulting DataFrame back to the dataframes dictionary\n",
    "dataframes['Origin'] = origin_wide_df\n",
    "del origin_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For df Sexos__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly create the pivot table with summation\n",
    "gender_wide_df = pd.pivot_table(\n",
    "    dataframes['Sexos'],\n",
    "    values='Total',\n",
    "    index=['ID', 'Year', 'Month'],\n",
    "    columns='Description',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Remove the original DataFrame from the dictionary\n",
    "dataframes.pop('Sexos', None)\n",
    "\n",
    "# Calculate the 'Total' column as the sum of the rows\n",
    "gender_wide_df['Total'] = gender_wide_df.sum(axis=1)\n",
    "\n",
    "# Translate columns to English\n",
    "gender_column_mapping = {\n",
    "    'Hombre': 'Male',\n",
    "    'Mujer': 'Female'\n",
    "}\n",
    "gender_wide_df.rename(columns=gender_column_mapping, inplace=True)\n",
    "\n",
    "# Assign the resulting DataFrame back to the dataframes dictionary\n",
    "dataframes['Gender'] = gender_wide_df[['Male', 'Female', 'Total']]\n",
    "del gender_wide_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__fix the total in Totals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes['Totals']['Total'] = dataframes['Ages']['Total']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 8:__ Output Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if path exists and create it if not\n",
    "if not os.path.exists(save_path_xl):\n",
    "    os.makedirs(save_path_xl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(save_path_xl):\n",
    "    os.makedirs(save_path_xl)\n",
    "\n",
    "with pd.ExcelWriter(f\"{save_path_xl}{filename_xlsx}\", engine='openpyxl') as writer:\n",
    "    for key in dataframes.keys():\n",
    "        dataframes[key].to_excel(writer, sheet_name=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Step 9:__ Output CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if path exists and create it if not\n",
    "if not os.path.exists(save_path_csv):\n",
    "    os.makedirs(save_path_csv)\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    filename_csv = f\"{key}.csv\"\n",
    "    full_path = f\"{save_path_csv}{filename_csv}\"\n",
    "    df.to_csv(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
